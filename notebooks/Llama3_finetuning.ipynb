{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNidox30OFyHzDZ5xbpTATM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 설치 필요 패키지"],"metadata":{"id":"9M-naYSm5_Bj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5VExEFra5if3"},"outputs":[],"source":["# pip install transformers datasets peft bitsandbytes accelerate scikit-learn\n","\n","import os\n","import torch\n","import pandas as pd\n","from datetime import datetime\n","import logging\n","import warnings\n","from datasets import Dataset\n","from sklearn.model_selection import train_test_split\n","\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n","    DataCollatorForLanguageModeling,\n","    Trainer\n",")\n","from peft import (\n","    prepare_model_for_kbit_training,\n","    get_peft_model,\n","    LoraConfig,\n","    TaskType\n",")"]},{"cell_type":"markdown","source":["# 기본 설정"],"metadata":{"id":"2YF4Ht_v6Ecw"}},{"cell_type":"code","source":["warnings.filterwarnings(\"ignore\")\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n","\n","# === 설정값 ===\n","MODEL_ID = \"MLP-KTLim/llama3-Bllossom\"\n","SYSTEM_PROMPT = \"당신은 유용한 AI 어시스턴트입니다. 사용자의 요구사항에 맞게 문장 변환을 해야합니다.\"\n","SAVE_DIR = \"./checkpoints\"\n","DATA_PATH = \"./data/sentence_pairs.csv\"  # 사용자가 여기에 CSV 파일 위치 맞게 설정"],"metadata":{"id":"x2wYdcyC6Cav"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 테스트용 문장"],"metadata":{"id":"NzAkFWFa6Jo5"}},{"cell_type":"code","source":["TEST_SENTENCES = [\n","    \"윤석열 대통령이 김영선 전 의원 공천을 직접 지시했다는 녹음이 공개됐습니다.\",\n","    \"KT&G 주가는 하반기 들어 24.7% 상승하며 52주 신고가를 기록했습니다.\"\n","]"],"metadata":{"id":"R6feBc5l6L6e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모델 및 토크나이저 설정"],"metadata":{"id":"jNLLzBVo6N-J"}},{"cell_type":"code","source":["def setup_model_and_tokenizer():\n","    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n","    quant_config = BitsAndBytesConfig(\n","        load_in_8bit=True,\n","        llm_int8_enable_fp32_cpu_offload=True\n","    )\n","    model = AutoModelForCausalLM.from_pretrained(\n","        MODEL_ID,\n","        torch_dtype=torch.float16,\n","        device_map=\"auto\",\n","        quantization_config=quant_config,\n","    )\n","    model = prepare_model_for_kbit_training(model)\n","    lora_config = LoraConfig(\n","        task_type=TaskType.CAUSAL_LM,\n","        r=16,\n","        lora_alpha=64,\n","        lora_dropout=0.1,\n","        target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n","    )\n","    model = get_peft_model(model, lora_config)\n","    return model, tokenizer"],"metadata":{"id":"CS4KT5oi6Pye"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 학습 데이터셋"],"metadata":{"id":"1l9Tmbwk6StO"}},{"cell_type":"code","source":["def create_weighted_training_pairs(df):\n","    training_pairs = []\n","    for _, row in df.iterrows():\n","        instruction = f\"'{row['adult_sentence']}'라는 문장을 어린이가 읽기 쉽도록 구어체로 바꿔줘. 어려운 단어는 쉽게 풀어서 설명해줘.\"\n","        prompt = f\"\"\"<system>{SYSTEM_PROMPT}</system>\\n<user>{instruction}</user>\\n<assistant>{row['kids_sentence']}</assistant>\"\"\"\n","        training_pairs.append({\"text\": prompt, \"weight\": float(row['similarity_score'])})\n","    return training_pairs\n","\n","def tokenize_and_add_weight(examples, tokenizer):\n","    tokenized = tokenizer(\n","        examples[\"text\"],\n","        truncation=True,\n","        padding=\"max_length\",\n","        max_length=256,\n","        return_tensors=\"pt\"\n","    )\n","    return {**tokenized, \"weight\": examples[\"weight\"]}\n","\n","class WeightedDataCollator(DataCollatorForLanguageModeling):\n","    def __call__(self, examples):\n","        weights = torch.tensor([ex.pop(\"weight\", 1.0) for ex in examples], dtype=torch.float)\n","        batch = super().__call__(examples)\n","        batch['weight'] = weights\n","        return batch\n","\n","class CustomTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        weights = inputs.pop(\"weight\", None)\n","        outputs = model(**inputs)\n","        loss = outputs.loss\n","        if weights is not None:\n","            loss = (loss.view(-1) * weights.view(-1)).mean()\n","        return (loss, outputs) if return_outputs else loss\n","\n","def train(training_pairs, model, tokenizer):\n","    train_data, val_data = train_test_split(training_pairs, test_size=0.2, random_state=42)\n","    train_dataset = Dataset.from_dict({\"text\": [x[\"text\"] for x in train_data], \"weight\": [x[\"weight\"] for x in train_data]})\n","    val_dataset = Dataset.from_dict({\"text\": [x[\"text\"] for x in val_data], \"weight\": [x[\"weight\"] for x in val_data]})\n","    train_tokenized = train_dataset.map(lambda x: tokenize_and_add_weight(x, tokenizer), batched=True, remove_columns=train_dataset.column_names)\n","    val_tokenized = val_dataset.map(lambda x: tokenize_and_add_weight(x, tokenizer), batched=True, remove_columns=val_dataset.column_names)\n","\n","    training_args = TrainingArguments(\n","        output_dir=SAVE_DIR,\n","        num_train_epochs=5,\n","        per_device_train_batch_size=16,\n","        per_device_eval_batch_size=16,\n","        gradient_accumulation_steps=4,\n","        learning_rate=2e-4,\n","        weight_decay=0.01,\n","        fp16=True,\n","        save_strategy=\"steps\",\n","        save_steps=100,\n","        evaluation_strategy=\"steps\",\n","        eval_steps=100,\n","        logging_steps=100,\n","        save_total_limit=2,\n","        load_best_model_at_end=True,\n","        metric_for_best_model=\"eval_loss\",\n","        remove_unused_columns=False,\n","        report_to=\"none\",\n","        gradient_checkpointing=True,\n","    )\n","\n","    trainer = CustomTrainer(\n","        model=model,\n","        tokenizer=tokenizer,\n","        args=training_args,\n","        train_dataset=train_tokenized,\n","        eval_dataset=val_tokenized,\n","        data_collator=WeightedDataCollator(tokenizer=tokenizer, mlm=False)\n","    )\n","\n","    trainer.train()\n","\n","    model.save_pretrained(f\"{SAVE_DIR}/llama3_finetuned\")\n","    tokenizer.save_pretrained(f\"{SAVE_DIR}/llama3_finetuned\")"],"metadata":{"id":"f4kuJ-fx6a7-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 추론용 함수"],"metadata":{"id":"-ETpLi-t6d6w"}},{"cell_type":"code","source":["def translate_to_kids_news(text, model, tokenizer):\n","    instruction = f\"'{text}'라는 문장을 어린이가 이해하기 쉽게 구어체로 바꿔줘.\"\n","    prompt = f\"\"\"<system>{SYSTEM_PROMPT}</system>\\n<user>{instruction}</user>\\n<assistant>\"\"\"\n","    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(model.device)\n","    outputs = model.generate(**inputs, max_new_tokens=200, do_sample=True, top_p=0.9, temperature=0.6)\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, \"\").split(\"</assistant>\")[0].strip()"],"metadata":{"id":"K4SQ2opN6iEL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 실행"],"metadata":{"id":"QRUrS-Ro6p7A"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    # 데이터 로드\n","    sentence_df = pd.read_csv(DATA_PATH)\n","    training_pairs = create_weighted_training_pairs(sentence_df)\n","\n","    # 모델 준비\n","    model, tokenizer = setup_model_and_tokenizer()\n","\n","    # 학습 실행\n","    train(training_pairs, model, tokenizer)\n","\n","    # 예시 추론\n","    for sent in TEST_SENTENCES:\n","        print(\"\\n[원문]\", sent)\n","        print(\"[어린이용]\", translate_to_kids_news(sent, model, tokenizer))"],"metadata":{"id":"1gvGfzAM6rXv"},"execution_count":null,"outputs":[]}]}